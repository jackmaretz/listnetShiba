{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.losses import categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nDCG metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discounted Cumulative Gain\n",
    "def dcg(score): \n",
    "    res=[]\n",
    "    for i in range((int(score.shape[0]))):\n",
    "        #print(i)\n",
    "        #print(score[i])\n",
    "        rel_i = (score)[i]\n",
    "        #print(rel_i)\n",
    "        log = K.log(sess.run(tf.to_float(i+2)))\n",
    "        #print(sess.run(log))\n",
    "        #frac = K.tf.divide(rel_i,log)\n",
    "        divResult = Lambda(lambda x: x[0]/x[1])([rel_i,log])\n",
    "\n",
    "        res.append(sess.run(divResult))\n",
    "    return np.sum(res)\n",
    "#ideal discounted cumulative gain\n",
    "def idcg(score_true):\n",
    "    frac=[]\n",
    "    y_sorted = sorted(sess.run(score_true),reverse=True)\n",
    "    #print((y_sorted))\n",
    "    for i in range(len(y_sorted)):\n",
    "        num = 2**(y_sorted[i])-1\n",
    "        #print(num)\n",
    "        denom = np.log(i+2)\n",
    "        #print (denom)\n",
    "        frac.append(num/denom)\n",
    "        #print(frac)\n",
    "    return np.sum(frac)\n",
    "#Normalized DCG\n",
    "def nDCG(score,score_true):\n",
    "    return dcg(score)/idcg(score_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 5) (373,)\n"
     ]
    }
   ],
   "source": [
    "train =  pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "df = pd.concat((train,test))\n",
    "df =df[[\"cosine_y\",\"query\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\",\"score\"]]\n",
    "\n",
    "X1 = train[[\"cosine_y\",\"query\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\"]]\n",
    "y1 = train[\"score\"]\n",
    "X = X1.to_numpy()\n",
    "y = y1.to_numpy()\n",
    "y = y.flatten()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, input_dim=4, kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_initializer=\"glorot_normal\")`\n",
      "  \n",
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, kernel_initializer=\"glorot_normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,337\n",
      "Trainable params: 5,071\n",
      "Non-trainable params: 266\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(64, input_dim=4, init='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#  hidden layer    \n",
    "model.add(Dense(64, init='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#  output layer\n",
    "model.add(Dense(5, init='glorot_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(Adam(lr = 0.0001), loss=\"binary_crossentropy\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "c = np.array(df.score)\n",
    "integer_encoded = c.reshape(len(c), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "y_onehot = pd.DataFrame(onehot_encoded,columns=[\"1\",\"2\",\"3\",\"4\",\"5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_y</th>\n",
       "      <th>query</th>\n",
       "      <th>numWordsQuery</th>\n",
       "      <th>numWordsCV</th>\n",
       "      <th>numCommonWords</th>\n",
       "      <th>score</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.363</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>2435</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>619</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>8796</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.358</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2558</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cosine_y  query  numWordsQuery  numWordsCV  numCommonWords  score    1  \\\n",
       "0     0.363     72              7        2435               1      3  0.0   \n",
       "1     0.483     71             10         619               3      3  0.0   \n",
       "2     0.474     71             10         977               3      1  1.0   \n",
       "3     0.358     70              2        8796               1      3  0.0   \n",
       "4     0.358     70              2        2558               1      1  1.0   \n",
       "\n",
       "     2    3    4    5  \n",
       "0  0.0  1.0  0.0  0.0  \n",
       "1  0.0  1.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  \n",
       "3  0.0  1.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([df, y_onehot], axis=1, join_axes=[df.index])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 36\n",
      "shape del test (4, 11)\n",
      "Train on 6 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      " - 0s - loss: 0.4998 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 2/5\n",
      " - 0s - loss: 0.4998 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 3/5\n",
      " - 0s - loss: 0.4997 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 4/5\n",
      " - 0s - loss: 0.4997 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 5/5\n",
      " - 0s - loss: 0.4997 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "     score\n",
      "316      1\n",
      "317      5\n",
      "318      1\n",
      "319      2\n",
      "[5, 5, 5, 5]\n",
      "metric nDCG: 0.37867296\n",
      "22 46\n",
      "shape del test (6, 11)\n",
      "Train on 10 samples, validate on 5 samples\n",
      "Epoch 1/5\n",
      " - 0s - loss: 0.4999 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 2/5\n",
      " - 0s - loss: 0.4999 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 3/5\n",
      " - 0s - loss: 0.4998 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 4/5\n",
      " - 0s - loss: 0.4998 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "Epoch 5/5\n",
      " - 0s - loss: 0.4998 - acc: 0.8000 - val_loss: 6.4121 - val_acc: 0.6000\n",
      "     score\n",
      "231      2\n",
      "232      1\n",
      "233      3\n",
      "234      2\n",
      "235      4\n",
      "236      3\n",
      "[1, 5, 5, 5, 5, 5]\n",
      "metric nDCG: 0.4868099\n",
      "15 47\n",
      "shape del test (4, 11)\n",
      "Train on 7 samples, validate on 3 samples\n",
      "Epoch 1/5\n",
      " - 0s - loss: 0.5013 - acc: 0.8000 - val_loss: 4.2747 - val_acc: 0.7333\n",
      "Epoch 2/5\n",
      " - 0s - loss: 0.5012 - acc: 0.8000 - val_loss: 4.2747 - val_acc: 0.7333\n",
      "Epoch 3/5\n",
      " - 0s - loss: 0.5012 - acc: 0.8000 - val_loss: 4.2747 - val_acc: 0.7333\n",
      "Epoch 4/5\n",
      " - 0s - loss: 0.5011 - acc: 0.8000 - val_loss: 4.2747 - val_acc: 0.7333\n",
      "Epoch 5/5\n",
      " - 0s - loss: 0.5010 - acc: 0.8000 - val_loss: 4.2747 - val_acc: 0.7333\n",
      "     score\n",
      "213      5\n",
      "214      5\n",
      "215      4\n",
      "216      4\n",
      "[1, 5, 1, 5]\n",
      "metric nDCG: 0.10551983\n"
     ]
    }
   ],
   "source": [
    "grouped = result.groupby(by='query')\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = [1,2,3,4,5]\n",
    "values = np.array(data)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "ndcg=[]\n",
    "for i,j in grouped:\n",
    "    if len(j)>13: #do model for queries with at least 10 docs rated\n",
    "        print(len(j),i)\n",
    "        n=int(70*len(j)/100)\n",
    "        n2=int(30*len(j)/100)\n",
    "\n",
    "        j=j.iloc[:n]\n",
    "        test1 = j[-(n2):]\n",
    "        test=(test1[[\"score\"]])\n",
    "        print(\"shape del test\",test1.shape)\n",
    "\n",
    "        test1=test1[[\"cosine_y\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\"]].to_numpy()\n",
    "        y = j[['1','2','3','4','5']].to_numpy()\n",
    "        #y = y_concat[:n]\n",
    "        X = j[[\"cosine_y\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\"]].to_numpy()\n",
    "        X, y = shuffle(X, y)\n",
    "        m=model.fit(X,y,validation_split=0.3, batch_size=1,epochs=5, shuffle=False, verbose=2)\n",
    "        predictions = model.predict(test1, verbose=0)\n",
    "        #print(\"Predicted values\",predictions) #empty prediction problemmmmmmmmmmmmmmb\n",
    "        print(test[[\"score\"]])\n",
    "        # invert first example\n",
    "        y_predicted=[]\n",
    "        for p in predictions:\n",
    "            y_predicted.append(argmax(p)+1)\n",
    "        print(y_predicted)\n",
    "        vec1 = tf.constant(y_predicted,dtype=tf.float32)\n",
    "        vec2 = tf.constant(np.array(test[[\"score\"]]),dtype=tf.float32)\n",
    "        print(\"metric nDCG:\",nDCG(vec1,vec2))\n",
    "        ndcg.append(nDCG(vec1,vec2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
