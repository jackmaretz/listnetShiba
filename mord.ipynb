{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORD : Multi-class Classifier for Ordinal Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mord as m\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "vali = pd.read_csv(\"vali.csv\")\n",
    "df = pd.concat((train,test,vali))\n",
    "df =df[[\"cosine_y\",\"query\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\",\"score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df[[\"cosine_y\",\"query\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\"]]\n",
    "y1 = df[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dcg(score):\n",
    "    res=[]\n",
    "    for i in range((int(score.shape[0]))):\n",
    "        #print(i)\n",
    "        #print(score[i])\n",
    "        rel_i = (score)[i]\n",
    "        #print(rel_i)\n",
    "        log = K.log(sess.run(tf.to_float(i+2)))\n",
    "        #print(sess.run(log))\n",
    "        #frac = K.tf.divide(rel_i,log)\n",
    "        divResult = Lambda(lambda x: x[0]/x[1])([rel_i,log])\n",
    "\n",
    "        res.append(sess.run(divResult))\n",
    "    return np.sum(res)\n",
    "def idcg(score_true):\n",
    "    frac=[]\n",
    "    y_sorted = sorted(sess.run(score_true),reverse=True)\n",
    "    #print((y_sorted))\n",
    "    for i in range(len(y_sorted)):\n",
    "        num = 2**(y_sorted[i])-1\n",
    "        #print(num)\n",
    "        denom = np.log(i+2)\n",
    "        #print (denom)\n",
    "        frac.append(num/denom)\n",
    "        #print(frac)\n",
    "    return np.sum(frac)\n",
    "def nDCG(score,score_true):\n",
    "    return dcg(score)/idcg(score_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lunghezza train set 7\n",
      "score train: [4 2 4 3 2 4 3]\n",
      "[array([2]), array([3]), array([3]), array([3])]\n",
      "[3 4 4 4]\n",
      "metric nDCG: 0.19111123612846848\n",
      "lunghezza train set 7\n",
      "score train: [3 2 2 3 4 3 4]\n",
      "[array([3]), array([3]), array([3]), array([3])]\n",
      "[2 2 2 5]\n",
      "metric nDCG: 0.21535261109459003\n",
      "lunghezza train set 10\n",
      "score train: [2 2 2 4 3 3 2 3 2 4]\n",
      "[array([3]), array([3]), array([3]), array([2]), array([2]), array([2])]\n",
      "[4 4 3 2 2 3]\n",
      "metric nDCG: 0.2631985886695165\n",
      "lunghezza train set 6\n",
      "score train: [4 4 3 3 4 5]\n",
      "[array([4]), array([4]), array([4]), array([4])]\n",
      "[3 3 4 3]\n",
      "metric nDCG: 0.39513820369402003\n",
      "lunghezza train set 6\n",
      "score train: [1 5 5 3 1 4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Values in y must be [0 1 2 3], instead got [0 2 3 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-228-916b4db5349f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lunghezza train set\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score train:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mmord1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mord\\threshold_based.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_class_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'AE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mord\\threshold_based.py\u001b[0m in \u001b[0;36mthreshold_fit\u001b[1;34m(X, y, alpha, n_class, mode, max_iter, verbose, tol, sample_weight)\u001b[0m\n\u001b[0;32m     98\u001b[0m         raise ValueError(\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m'Values in y must be %s, instead got %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             % (np.arange(unique_y.size), unique_y))\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Values in y must be [0 1 2 3], instead got [0 2 3 4]"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby(by='query')\n",
    "mord1 = m.LogisticAT()\n",
    "ndcgMord=[]\n",
    "\n",
    "for i,j in grouped:\n",
    "    if len(j)>=10:\n",
    "        x=j.drop([\"query\",\"score\"],axis=1)\n",
    "        X = x.values\n",
    "        y = j.score.values#.reshape(-1, 1)\n",
    "        #print(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y  , test_size=0.33, random_state=42)\n",
    "        print(\"lunghezza train set\",len(X_train))\n",
    "        print(\"score train:\",y_train)\n",
    "        mord1.fit(X_train,y_train)\n",
    "        nu=0\n",
    "        pred=[]\n",
    "        true =y_test\n",
    "        for row in X_test:\n",
    "            #print(\"input x:\",row)\n",
    "            pred.append(mord1.predict(row))\n",
    "            #print(\"predict y:\",pred)\n",
    "            #print(\"true y:\", y_test[nu])\n",
    "            nu=nu+1\n",
    "        print(pred)\n",
    "        print(true)\n",
    "        vec1 = tf.constant(np.array(pred),dtype=tf.float32)\n",
    "        vec2 = tf.constant(np.array(true),dtype=tf.float32)\n",
    "        print(\"metric nDCG:\",nDCG(vec1,vec2))\n",
    "        ndcgMord.append(nDCG(vec1,vec2))\n",
    "        \n",
    "        \n",
    "    #else:\n",
    "        #print(i,\"not enough rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26620015989664875"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ndcgMord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"cosine_y\",\"query\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\"]]\n",
    "y = df[\"score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y  , test_size=0.33, random_state=42)\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature importance: [0.27628223 0.18950626 0.14643351 0.31838517 0.06939283]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=50,criterion = 'entropy', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"feature importance:\",clf.feature_importances_)\n",
    "predictions = (clf.predict(X_test))\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Random Forest Trained on Original Data\n",
      "Average absolute error: 1.05 degrees.\n",
      "Accuracy: 54.83 %.\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Metrics for Random Forest Trained on Original Data')\n",
    "print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110     50.000000\n",
       "79      66.666667\n",
       "5       33.333333\n",
       "77      20.000000\n",
       "181     20.000000\n",
       "284     50.000000\n",
       "10      80.000000\n",
       "100      0.000000\n",
       "78      20.000000\n",
       "350     60.000000\n",
       "55     100.000000\n",
       "118      0.000000\n",
       "109     50.000000\n",
       "29       0.000000\n",
       "371      0.000000\n",
       "234     50.000000\n",
       "30      75.000000\n",
       "212     66.666667\n",
       "184      0.000000\n",
       "86      25.000000\n",
       "2      200.000000\n",
       "1       40.000000\n",
       "165      0.000000\n",
       "37      25.000000\n",
       "370     66.666667\n",
       "318    100.000000\n",
       "72      50.000000\n",
       "135     40.000000\n",
       "186     50.000000\n",
       "70      33.333333\n",
       "          ...    \n",
       "250    100.000000\n",
       "287    300.000000\n",
       "158    200.000000\n",
       "30      20.000000\n",
       "167      0.000000\n",
       "54     100.000000\n",
       "124      0.000000\n",
       "46      75.000000\n",
       "93       0.000000\n",
       "264      0.000000\n",
       "108     33.333333\n",
       "272      0.000000\n",
       "40       0.000000\n",
       "110      0.000000\n",
       "66      25.000000\n",
       "26     100.000000\n",
       "9      100.000000\n",
       "33      33.333333\n",
       "107      0.000000\n",
       "265      0.000000\n",
       "2        0.000000\n",
       "9       40.000000\n",
       "69      80.000000\n",
       "231     50.000000\n",
       "113      0.000000\n",
       "278     50.000000\n",
       "170     33.333333\n",
       "352    100.000000\n",
       "260      0.000000\n",
       "149     33.333333\n",
       "Name: score, Length: 200, dtype: float64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39344262 0.29508197 0.36065574 0.29508197 0.41666667 0.51666667\n",
      " 0.45       0.41666667 0.48333333 0.45      ]\n"
     ]
    }
   ],
   "source": [
    "crossvalidation=KFold(n_splits=10,shuffle=True,random_state=1)\n",
    "score=(cross_val_score(clf,X,y,scoring='accuracy', cv=crossvalidation,n_jobs=1))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC=GradientBoostingClassifier()\n",
    "search_grid={'n_estimators':[100,500,1000],'learning_rate':[.001,0.01,.1],'max_depth':[1,3,5],'subsample':[.5,.75,1],'random_state':[1]}\n",
    "search=GridSearchCV(estimator=GBC,param_grid=search_grid,scoring='accuracy',n_jobs=3,cv=crossvalidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giaco\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 100,\n",
       " 'random_state': 1,\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X,y)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4225136612021858"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada2=GradientBoostingClassifier(n_estimators=60,learning_rate=0.01,subsample=0.5,max_depth=5,random_state=1)\n",
    "score=np.mean(cross_val_score(ada2,X,y,scoring='accuracy',cv=crossvalidation,n_jobs=1))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian kernel\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"cosine_y\",\"query\",\"numWordsQuery\",\"numWordsCV\",\"numCommonWords\"]]\n",
    "y = df[\"score\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y  , test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier =  SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.83      0.43        59\n",
      "           2       0.23      0.09      0.13        34\n",
      "           3       0.00      0.00      0.00        35\n",
      "           4       0.23      0.09      0.13        33\n",
      "           5       0.00      0.00      0.00        39\n",
      "\n",
      "   micro avg       0.28      0.28      0.28       200\n",
      "   macro avg       0.15      0.20      0.14       200\n",
      "weighted avg       0.16      0.28      0.17       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "mat = (confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=np.diag(mat) / mat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83050847, 0.08823529, 0.        , 0.09090909, 0.        ])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59, 34, 35, 33, 39], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
